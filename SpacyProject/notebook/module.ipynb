{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a envronment with ppthon 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install spacy_transformers\n",
    "# !pip install -U pip setuptools wheel\n",
    "# !pip install -U 'spacy[apple]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_training_data = json.load(open('/Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/training/ResumeJsondataV1.json')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Create the config file using the base config file\n",
    "\n",
    "You can execute in notebook or in terminal, you will get the config file in the desire folder\n",
    "\n",
    "!python -m spacy init fill-config /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyConfig/base_config.cfg /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyConfig/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy init fill-config /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyConfig/base_config.cfg /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyConfig/config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the wheter the data annotetion is correcte, will check two entity annotetion didnt got mearched each othere in the single resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc(file,data):\n",
    "  nlp = spacy.blank('en')\n",
    "  db = DocBin()\n",
    "\n",
    "  for text, annot in tqdm(data):\n",
    "    doc = nlp.make_doc(text)\n",
    "    annot = annot['entities']\n",
    "\n",
    "    ents =[]\n",
    "    entity_indices = []\n",
    "\n",
    "    for start, end, label in annot:\n",
    "      skip_entity=False\n",
    "      for idx in range(start, end):\n",
    "        if idx in entity_indices:\n",
    "          skip_entity=True\n",
    "          break\n",
    "      if skip_entity==True:\n",
    "        continue\n",
    "      entity_indices = entity_indices+list(range(start,end))\n",
    "\n",
    "      try:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "      if span is None:\n",
    "        err_data = str([start, end]) + \" \"+str(text)+\"\\n\"\n",
    "        file.write(err_data)\n",
    "\n",
    "      else:\n",
    "        ents.append(span)\n",
    "\n",
    "    try:\n",
    "      doc.ents = ents\n",
    "      db.add(doc)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(resume_training_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amarnathgowda/anaconda3/envs/newenvr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 21/21 [00:00<00:00, 99.97it/s] \n",
      "100%|██████████| 10/10 [00:00<00:00, 90.21it/s]\n"
     ]
    }
   ],
   "source": [
    "file = open('/Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyTrainTestdata/error.txt', 'w')\n",
    "\n",
    "db = get_spacy_doc(file, train)\n",
    "db.to_disk('/Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyTrainTestdata/train_data.spacy')\n",
    "\n",
    "db = get_spacy_doc(file, test)\n",
    "db.to_disk('/Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyTrainTestdata/test_data.spacy')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model using our train and test data, below command can execute in the notebook or terminal\n",
    "\n",
    "!python -m spacy train /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyConfig/config.cfg --output /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/modeloutput --paths.train /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyTrainTestdata/train_data.spacy --paths.dev /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyTrainTestdata/test_data.spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy train /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyConfig/config.cfg --output /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/modeloutput --paths.train /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyTrainTestdata/train_data.spacy --paths.dev /Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/spacyTrainTestdata/test_data.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('/Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/SpacyProject/modeloutput/model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laxmi Kant    ->>>>>  NAME\n",
      "Microsoft    ->>>>>  ORGANIZATION\n",
      "10 years of experience    ->>>>>  EXPERIENCE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('my name is Laxmi Kant Tiwari. I worked at Microsoft. I have 10 years of experience')\n",
    "for ent in doc.ents:\n",
    "  print(ent.text, \"   ->>>>> \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf4\n",
      "  Downloading PyPDF4-1.27.0.tar.gz (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pypdf4\n",
      "  Building wheel for pypdf4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypdf4: filename=PyPDF4-1.27.0-py3-none-any.whl size=61226 sha256=268be18406993fe8123b6d4d41a45f23ac1e86f8ad3bd250d4a07baed5059714\n",
      "  Stored in directory: /Users/amarnathgowda/Library/Caches/pip/wheels/cd/0e/4a/e6f842a6035ccffff0dab29c39dd06c3427560a82783355a83\n",
      "Successfully built pypdf4\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pypdf4\n",
      "Successfully installed pypdf4-1.27.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "Alice Clark\n",
      " \n",
      "AI\n",
      " \n",
      "/ Machine Learning\n",
      " \n",
      " \n",
      "Delhi, India Em\n",
      "ail me \n",
      "on Indeed\n",
      " \n",
      "\n",
      " \n",
      "20+ y\n",
      "ears of experience in data han\n",
      "dling, design\n",
      ", and \n",
      "development\n",
      " \n",
      "\n",
      " \n",
      "Data Wa\n",
      "rehou\n",
      "se: \n",
      "Data analysis\n",
      ", star\n",
      "/snow fla\n",
      "ke scema data \n",
      "modelling\n",
      " \n",
      "and design specific to \n",
      "data warehousing\n",
      " \n",
      "and business intelligence\n",
      " \n",
      "\n",
      " \n",
      "Database: Experience in database designing, scalability, back\n",
      "-\n",
      "up and recovery, writing and\n",
      " \n",
      "optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes.\n",
      " \n",
      "Cloud platform: Worked on Microsoft Azure cloud services like Document \n",
      "DB, SQL Azure, \n",
      "Stream\n",
      " \n",
      "Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake \n",
      "analytics(U\n",
      "-\n",
      "SQL)\n",
      " \n",
      "Willing to relocate anywhere\n",
      " \n",
      " \n",
      "W\n",
      "ORK EXPERIE\n",
      "NCE\n",
      " \n",
      "Software Engineer\n",
      " \n",
      "Microsoft \n",
      "\n",
      " \n",
      "Bangalore,\n",
      " \n",
      "Karnataka\n",
      " \n",
      "January\n",
      " \n",
      "20\n",
      "0\n",
      "0 to Present\n",
      " \n",
      "1. Microsoft Rewards Live dashboards:\n",
      " \n",
      "Description: \n",
      "-\n",
      " \n",
      "Microsoft rewards is loyalty program that rewards Users for browsing and shopping\n",
      " \n",
      "online. Microsoft Rewards members can earn points when searching with Bing, browsing with\n",
      " \n",
      "Microsoft Edge and making purchases at the Xbox Store, the Windows St\n",
      "ore and the Microsoft\n",
      " \n",
      "Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft\n",
      " \n",
      "rewards website. Rewards live dashboards gives a live picture of usage world\n",
      "-\n",
      "wide and by\n",
      " \n",
      "markets like US, Canada, Australia, new user regis\n",
      "tration count, top/bottom performing rewards\n",
      " \n",
      "offers, orders stats and weekly trends of user activities, orders and new user registrations. the\n",
      " \n",
      "PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.\n",
      " \n",
      "Technology/Tools used\n",
      " \n",
      " \n",
      "EDUCATI\n",
      "ON\n",
      " \n",
      "Indian Inst\n",
      "itute o\n",
      "f Technolo\n",
      "gy \n",
      "\n",
      " \n",
      "Mumbai\n",
      " \n",
      "2001\n",
      " \n",
      " \n",
      "SKILLS\n",
      " \n",
      "Machine Learning, \n",
      "Natural\n",
      " \n",
      "Language\n",
      " \n",
      "Processing, and \n",
      "Big Data Handling\n",
      " \n",
      " \n",
      "\n",
      "1\n",
      "Alice Clark\n",
      " \n",
      "AI\n",
      " \n",
      "/ Machine Learning\n",
      " \n",
      " \n",
      "Delhi, India Em\n",
      "ail me \n",
      "on Indeed\n",
      " \n",
      "\n",
      " \n",
      "20+ y\n",
      "ears of experience in data han\n",
      "dling, design\n",
      ", and \n",
      "development\n",
      " \n",
      "\n",
      " \n",
      "Data Wa\n",
      "rehou\n",
      "se: \n",
      "Data analysis\n",
      ", star\n",
      "/snow fla\n",
      "ke scema data \n",
      "modelling\n",
      " \n",
      "and design specific to \n",
      "data warehousing\n",
      " \n",
      "and business intelligence\n",
      " \n",
      "\n",
      " \n",
      "Database: Experience in database designing, scalability, back\n",
      "-\n",
      "up and recovery, writing and\n",
      " \n",
      "optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes.\n",
      " \n",
      "Cloud platform: Worked on Microsoft Azure cloud services like Document \n",
      "DB, SQL Azure, \n",
      "Stream\n",
      " \n",
      "Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake \n",
      "analytics(U\n",
      "-\n",
      "SQL)\n",
      " \n",
      "Willing to relocate anywhere\n",
      " \n",
      " \n",
      "W\n",
      "ORK EXPERIE\n",
      "NCE\n",
      " \n",
      "Software Engineer\n",
      " \n",
      "Microsoft \n",
      "\n",
      " \n",
      "Bangalore,\n",
      " \n",
      "Karnataka\n",
      " \n",
      "January\n",
      " \n",
      "20\n",
      "0\n",
      "0 to Present\n",
      " \n",
      "1. Microsoft Rewards Live dashboards:\n",
      " \n",
      "Description: \n",
      "-\n",
      " \n",
      "Microsoft rewards is loyalty program that rewards Users for browsing and shopping\n",
      " \n",
      "online. Microsoft Rewards members can earn points when searching with Bing, browsing with\n",
      " \n",
      "Microsoft Edge and making purchases at the Xbox Store, the Windows St\n",
      "ore and the Microsoft\n",
      " \n",
      "Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft\n",
      " \n",
      "rewards website. Rewards live dashboards gives a live picture of usage world\n",
      "-\n",
      "wide and by\n",
      " \n",
      "markets like US, Canada, Australia, new user regis\n",
      "tration count, top/bottom performing rewards\n",
      " \n",
      "offers, orders stats and weekly trends of user activities, orders and new user registrations. the\n",
      " \n",
      "PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.\n",
      " \n",
      "Technology/Tools used\n",
      " \n",
      " \n",
      "EDUCATI\n",
      "ON\n",
      " \n",
      "Indian Inst\n",
      "itute o\n",
      "f Technolo\n",
      "gy \n",
      "\n",
      " \n",
      "Mumbai\n",
      " \n",
      "2001\n",
      " \n",
      " \n",
      "SKILLS\n",
      " \n",
      "Machine Learning, \n",
      "Natural\n",
      " \n",
      "Language\n",
      " \n",
      "Processing, and \n",
      "Big Data Handling\n",
      " \n",
      " \n",
      "ADDITIONAL INFO\n",
      "RMATION\n",
      " \n",
      "Professional Skills\n",
      " \n",
      "\n",
      " \n",
      "skills with ability to interact with individuals at all the levels\n",
      " \n",
      "\n",
      "ger and team members and\n",
      " \n",
      "good performer both in team and independent job environments\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PyPDF4 import PdfFileReader\n",
    "pdf = PdfFileReader(\"/Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/files/Alice Clark CV.pdf\")\n",
    "print(pdf.numPages)\n",
    "text =''\n",
    "for page in range(0,pdf.numPages):\n",
    "    \n",
    "    first_page = pdf.getPage(page)\n",
    "    print(page)\n",
    "    text = text+first_page.extractText()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning, \n",
      "Natural\n",
      " \n",
      "Language\n",
      " \n",
      "Processing, and \n",
      "Big Data Handling\n",
      " \n",
      " \n",
      "ADDITIONAL INFO\n",
      "RMATION\n",
      " \n",
      "Professional Skills\n",
      " \n",
      "\n",
      " \n",
      "skills with ability to interact with individuals at all the levels\n",
      " \n",
      "\n",
      "ger and team members and\n",
      " \n",
      "good performer both in team and independent job environments\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "  ->>>>>  SKILLS\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:    \n",
    "    print(ent.text, \" ->>>>> \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Saman Ayubi\\n\\nFrontend Developer\\nBeing motivated with good attitude and strong analytical and development skill to work with the most competent professionals leveraging my experience\\nto upgrade my technical and management skills for a continued professional growth and advancement.\\n\\nayubisaman90@gmail.com\\n\\n8142316777\\n\\nBangalore\\n\\nlinkedin.com/in/saman-ayubi-64498992\\n\\nWORK EXPERIENCE\\nAssociate Consultant\\nCapgemini\\n05/2018 \\xe2\\x80\\x93 Present\\n\\nTeam Lead\\nIntellect Design Arena\\n05/2016 \\xe2\\x80\\x93 05/2018\\n\\nConsultant\\nIntellect Design Arena\\n06/2015 \\xe2\\x80\\x93 04/2016\\n\\nEDUCATION\\nElectronics & Communication (B.tech)\\nChandigarh Engineering College\\n08/2011 \\xe2\\x80\\x93 05/2015\\n\\nSKILLS\\n\\nAngular 2/4/5/7\\n\\nJavaScript\\n\\nHtml 5\\n\\nCss 3\\n\\nBanglore\\n\\nExt JS 5/6\\n\\nAgile\\n\\nDocker\\n\\nJenkins\\n\\nGit\\n\\nSVN\\n\\nAngular Material\\n\\nHighcharts\\n\\nGoogle Maps\\n\\nGoogle Analytics\\n\\nAmcharts\\n\\nPredix Ui Components\\n\\nHyderabad\\n\\nHyderabad\\n\\nMohali\\n\\nPROJECTS\\n1. Engage Subsea\\nClient - GE Power\\n06/2018 \\xe2\\x80\\x93 Present\\nRoles & Responsibilities\\n\\nWork closely with the Client to check the technical feasibility and\\nimplementation of their requirements. Design & Development Of\\nResponsive web pages.\\nImplementation of di\\xef\\xac\\x80erent charts, google map and google analytics\\nintegration in the application.\\nChoose better component while designing the screen. Creating new\\nLibrary component and creating .tgz to be used in the project.\\nCode Review of the Team Members and Deployment on dev, qa and\\nproduction environment.\\nDatabase interaction.\\n\\n2. Wealth Management Application\\nClient - St. James Place\\n05/2016 \\xe2\\x80\\x93 05/2018\\nRoles & Responsibilities\\n\\nWorked as UI Team lead, handled a team of 7 UI Developers. Singly\\nresponsible for all the front-end delivery of the project. Served as a\\none-point contact for requirements between client, teams, QA, and L2\\nsupport.\\nWorked closely with the Client and their UX Team to check the\\ntechnical feasibility and implementation of their requirements, being\\npart of a analysis, design and implementation.Lead and facilitated\\nclient workshops for requirement analysis and capture requirement.\\n\\n3. QUOTES AND ILLUSTRATION\\nProduct - Intellect Design Arena\\n06/2015 \\xe2\\x80\\x93 04/2016\\nRoles & Responsibilities\\n\\nWorked as a Consultant .Lead for Designing UI Screen and developing\\nUI Components.\\nMaintaining Cross bowser compatibility of the application. Work as\\ncore team member in overall development. Adhere with coding\\nstandard.\\n\\n\\x0c'\n",
      "Saman AyubiFrontend DeveloperBeing motivated with good attitude and strong analytical and development skill to work with the most competent professionals leveraging my experienceto upgrade my technical and management skills for a continued professional growth and advancement.ayubisaman90@gmail.com8142316777Bangalorelinkedin.com/in/saman-ayubi-64498992WORK EXPERIENCEAssociate ConsultantCapgemini05/2018 – PresentTeam LeadIntellect Design Arena05/2016 – 05/2018ConsultantIntellect Design Arena06/2015 – 04/2016EDUCATIONElectronics & Communication (B.tech)Chandigarh Engineering College08/2011 – 05/2015SKILLSAngular 2/4/5/7JavaScriptHtml 5Css 3BangloreExt JS 5/6AgileDockerJenkinsGitSVNAngular MaterialHighchartsGoogle MapsGoogle AnalyticsAmchartsPredix Ui ComponentsHyderabadHyderabadMohaliPROJECTS1. Engage SubseaClient - GE Power06/2018 – PresentRoles & ResponsibilitiesWork closely with the Client to check the technical feasibility andimplementation of their requirements. Design & Development OfResponsive web pages.Implementation of diﬀerent charts, google map and google analyticsintegration in the application.Choose better component while designing the screen. Creating newLibrary component and creating .tgz to be used in the project.Code Review of the Team Members and Deployment on dev, qa andproduction environment.Database interaction.2. Wealth Management ApplicationClient - St. James Place05/2016 – 05/2018Roles & ResponsibilitiesWorked as UI Team lead, handled a team of 7 UI Developers. Singlyresponsible for all the front-end delivery of the project. Served as aone-point contact for requirements between client, teams, QA, and L2support.Worked closely with the Client and their UX Team to check thetechnical feasibility and implementation of their requirements, beingpart of a analysis, design and implementation.Lead and facilitatedclient workshops for requirement analysis and capture requirement.3. QUOTES AND ILLUSTRATIONProduct - Intellect Design Arena06/2015 – 04/2016Roles & ResponsibilitiesWorked as a Consultant .Lead for Designing UI Screen and developingUI Components.Maintaining Cross bowser compatibility of the application. Work ascore team member in overall development. Adhere with codingstandard.\f\n"
     ]
    }
   ],
   "source": [
    "import textract\n",
    "\n",
    "text=textract.process(\"/Users/amarnathgowda/Desktop/ML_Project/ResumeParsing/files/SamanAyubi_4_6_.pdf\")\n",
    "\n",
    "print(text)\n",
    "\n",
    "text = text.decode()\n",
    "text = text.split('\\n')\n",
    "text = \"\".join(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saman AyubiFrontend  ->>>>>  NAME\n",
      "(B.tech)Chandigarh Engineering College08/2011  ->>>>>  QUALIFICATION\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:    \n",
    "    print(ent.text, \" ->>>>> \", ent.label_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResumeParsingEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
